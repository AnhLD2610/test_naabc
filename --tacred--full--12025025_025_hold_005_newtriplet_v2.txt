#############params############
cuda
Task=Tacred, 5-shot
Encoding model: bert
pattern=hybridprompt
mem=1, margin=0.3, gen=0, gen_num=2
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
CurrentTrain: epoch  0, batch     0 | loss: 19.4271469CurrentTrain: epoch  0, batch     1 | loss: 20.5578461CurrentTrain: epoch  0, batch     2 | loss: 20.0964947CurrentTrain: epoch  0, batch     3 | loss: 19.2562504CurrentTrain: epoch  0, batch     4 | loss: 15.9273119CurrentTrain: epoch  0, batch     5 | loss: 13.8994122CurrentTrain: epoch  0, batch     6 | loss: 14.7900372CurrentTrain: epoch  0, batch     7 | loss: 11.9055023CurrentTrain: epoch  0, batch     8 | loss: 14.2203016CurrentTrain: epoch  0, batch     9 | loss: 11.8874416CurrentTrain: epoch  0, batch    10 | loss: 12.3198605CurrentTrain: epoch  0, batch    11 | loss: 11.9755945CurrentTrain: epoch  0, batch    12 | loss: 11.3006630CurrentTrain: epoch  0, batch    13 | loss: 11.6141396CurrentTrain: epoch  0, batch    14 | loss: 11.2379370CurrentTrain: epoch  0, batch    15 | loss: 12.0683365CurrentTrain: epoch  0, batch    16 | loss: 11.7228937CurrentTrain: epoch  0, batch    17 | loss: 12.0036650CurrentTrain: epoch  0, batch    18 | loss: 10.4546299CurrentTrain: epoch  0, batch    19 | loss: 11.1739073CurrentTrain: epoch  0, batch    20 | loss: 10.8319321CurrentTrain: epoch  0, batch    21 | loss: 10.1630630CurrentTrain: epoch  0, batch    22 | loss: 11.5837746CurrentTrain: epoch  0, batch    23 | loss: 10.7716436CurrentTrain: epoch  0, batch    24 | loss: 10.6810541CurrentTrain: epoch  0, batch    25 | loss: 10.1194239CurrentTrain: epoch  0, batch    26 | loss: 10.4987936CurrentTrain: epoch  0, batch    27 | loss: 10.0530930CurrentTrain: epoch  0, batch    28 | loss: 10.7566366CurrentTrain: epoch  0, batch    29 | loss: 9.5377684CurrentTrain: epoch  0, batch    30 | loss: 9.1850367CurrentTrain: epoch  0, batch    31 | loss: 9.5736914CurrentTrain: epoch  0, batch    32 | loss: 8.7268715CurrentTrain: epoch  0, batch    33 | loss: 9.1987343CurrentTrain: epoch  0, batch    34 | loss: 7.6797676CurrentTrain: epoch  0, batch    35 | loss: 9.7513466CurrentTrain: epoch  0, batch    36 | loss: 8.0320988CurrentTrain: epoch  0, batch    37 | loss: 6.5510316CurrentTrain: epoch  1, batch     0 | loss: 7.6871696CurrentTrain: epoch  1, batch     1 | loss: 8.4062548CurrentTrain: epoch  1, batch     2 | loss: 8.3447657CurrentTrain: epoch  1, batch     3 | loss: 8.5745373CurrentTrain: epoch  1, batch     4 | loss: 7.1457682CurrentTrain: epoch  1, batch     5 | loss: 8.8620358CurrentTrain: epoch  1, batch     6 | loss: 7.2862601CurrentTrain: epoch  1, batch     7 | loss: 7.8727708CurrentTrain: epoch  1, batch     8 | loss: 8.0745144CurrentTrain: epoch  1, batch     9 | loss: 6.6420040CurrentTrain: epoch  1, batch    10 | loss: 6.8836522CurrentTrain: epoch  1, batch    11 | loss: 7.2058945CurrentTrain: epoch  1, batch    12 | loss: 6.8148937CurrentTrain: epoch  1, batch    13 | loss: 7.2030869CurrentTrain: epoch  1, batch    14 | loss: 6.7355261CurrentTrain: epoch  1, batch    15 | loss: 7.3895464CurrentTrain: epoch  1, batch    16 | loss: 6.3967810CurrentTrain: epoch  1, batch    17 | loss: 7.2629118CurrentTrain: epoch  1, batch    18 | loss: 6.9336739CurrentTrain: epoch  1, batch    19 | loss: 7.2488170CurrentTrain: epoch  1, batch    20 | loss: 6.5812640CurrentTrain: epoch  1, batch    21 | loss: 5.6283607CurrentTrain: epoch  1, batch    22 | loss: 6.8306751CurrentTrain: epoch  1, batch    23 | loss: 7.0462370CurrentTrain: epoch  1, batch    24 | loss: 6.4944701CurrentTrain: epoch  1, batch    25 | loss: 5.8796821CurrentTrain: epoch  1, batch    26 | loss: 6.2904825CurrentTrain: epoch  1, batch    27 | loss: 5.7148547CurrentTrain: epoch  1, batch    28 | loss: 5.9413500CurrentTrain: epoch  1, batch    29 | loss: 6.5219889CurrentTrain: epoch  1, batch    30 | loss: 6.1857705CurrentTrain: epoch  1, batch    31 | loss: 6.5532470CurrentTrain: epoch  1, batch    32 | loss: 6.2296972CurrentTrain: epoch  1, batch    33 | loss: 6.3529425CurrentTrain: epoch  1, batch    34 | loss: 6.1388187CurrentTrain: epoch  1, batch    35 | loss: 6.7913675CurrentTrain: epoch  1, batch    36 | loss: 8.5852909CurrentTrain: epoch  1, batch    37 | loss: 6.1942172CurrentTrain: epoch  2, batch     0 | loss: 5.2816839CurrentTrain: epoch  2, batch     1 | loss: 7.4888659CurrentTrain: epoch  2, batch     2 | loss: 5.6610694CurrentTrain: epoch  2, batch     3 | loss: 6.7841029CurrentTrain: epoch  2, batch     4 | loss: 5.9640493CurrentTrain: epoch  2, batch     5 | loss: 5.6301470CurrentTrain: epoch  2, batch     6 | loss: 5.2555022CurrentTrain: epoch  2, batch     7 | loss: 6.0509334CurrentTrain: epoch  2, batch     8 | loss: 5.4008284CurrentTrain: epoch  2, batch     9 | loss: 5.5214472CurrentTrain: epoch  2, batch    10 | loss: 6.9744329CurrentTrain: epoch  2, batch    11 | loss: 6.6495595CurrentTrain: epoch  2, batch    12 | loss: 6.4024134CurrentTrain: epoch  2, batch    13 | loss: 6.3141866CurrentTrain: epoch  2, batch    14 | loss: 6.5842266CurrentTrain: epoch  2, batch    15 | loss: 5.6581411CurrentTrain: epoch  2, batch    16 | loss: 6.3737030CurrentTrain: epoch  2, batch    17 | loss: 5.3905926CurrentTrain: epoch  2, batch    18 | loss: 6.3138852CurrentTrain: epoch  2, batch    19 | loss: 6.3194456CurrentTrain: epoch  2, batch    20 | loss: 6.4874687CurrentTrain: epoch  2, batch    21 | loss: 6.7955570CurrentTrain: epoch  2, batch    22 | loss: 6.1835895CurrentTrain: epoch  2, batch    23 | loss: 6.3498898CurrentTrain: epoch  2, batch    24 | loss: 5.3098545CurrentTrain: epoch  2, batch    25 | loss: 5.5580201CurrentTrain: epoch  2, batch    26 | loss: 5.0924029CurrentTrain: epoch  2, batch    27 | loss: 6.6622005CurrentTrain: epoch  2, batch    28 | loss: 5.7900920CurrentTrain: epoch  2, batch    29 | loss: 6.2346015CurrentTrain: epoch  2, batch    30 | loss: 5.4297080CurrentTrain: epoch  2, batch    31 | loss: 5.2355571CurrentTrain: epoch  2, batch    32 | loss: 5.4522629CurrentTrain: epoch  2, batch    33 | loss: 5.1623139CurrentTrain: epoch  2, batch    34 | loss: 5.9692535CurrentTrain: epoch  2, batch    35 | loss: 6.6536388CurrentTrain: epoch  2, batch    36 | loss: 6.3156714CurrentTrain: epoch  2, batch    37 | loss: 5.2560134CurrentTrain: epoch  3, batch     0 | loss: 5.4479651CurrentTrain: epoch  3, batch     1 | loss: 5.9312172CurrentTrain: epoch  3, batch     2 | loss: 5.8315520CurrentTrain: epoch  3, batch     3 | loss: 6.0024743CurrentTrain: epoch  3, batch     4 | loss: 5.1473994CurrentTrain: epoch  3, batch     5 | loss: 5.0434012CurrentTrain: epoch  3, batch     6 | loss: 6.1744170CurrentTrain: epoch  3, batch     7 | loss: 5.6676440CurrentTrain: epoch  3, batch     8 | loss: 5.7097631CurrentTrain: epoch  3, batch     9 | loss: 5.3504496CurrentTrain: epoch  3, batch    10 | loss: 5.1166668CurrentTrain: epoch  3, batch    11 | loss: 5.3531623CurrentTrain: epoch  3, batch    12 | loss: 5.3766894CurrentTrain: epoch  3, batch    13 | loss: 5.7481174CurrentTrain: epoch  3, batch    14 | loss: 5.1055803CurrentTrain: epoch  3, batch    15 | loss: 5.0931311CurrentTrain: epoch  3, batch    16 | loss: 6.4124050CurrentTrain: epoch  3, batch    17 | loss: 5.5349331CurrentTrain: epoch  3, batch    18 | loss: 5.9204950CurrentTrain: epoch  3, batch    19 | loss: 5.2413759CurrentTrain: epoch  3, batch    20 | loss: 6.0367360CurrentTrain: epoch  3, batch    21 | loss: 5.0436993CurrentTrain: epoch  3, batch    22 | loss: 5.5634823CurrentTrain: epoch  3, batch    23 | loss: 5.4055214CurrentTrain: epoch  3, batch    24 | loss: 5.2750707CurrentTrain: epoch  3, batch    25 | loss: 5.2799478CurrentTrain: epoch  3, batch    26 | loss: 6.0209646CurrentTrain: epoch  3, batch    27 | loss: 7.0545182CurrentTrain: epoch  3, batch    28 | loss: 6.0143242CurrentTrain: epoch  3, batch    29 | loss: 5.8204923CurrentTrain: epoch  3, batch    30 | loss: 4.9521317CurrentTrain: epoch  3, batch    31 | loss: 5.8079758CurrentTrain: epoch  3, batch    32 | loss: 5.7709780CurrentTrain: epoch  3, batch    33 | loss: 5.1005487CurrentTrain: epoch  3, batch    34 | loss: 5.3806634CurrentTrain: epoch  3, batch    35 | loss: 5.7397327CurrentTrain: epoch  3, batch    36 | loss: 5.1666465CurrentTrain: epoch  3, batch    37 | loss: 5.1582489CurrentTrain: epoch  4, batch     0 | loss: 4.9774303CurrentTrain: epoch  4, batch     1 | loss: 5.3594174CurrentTrain: epoch  4, batch     2 | loss: 5.4444113CurrentTrain: epoch  4, batch     3 | loss: 5.3136263CurrentTrain: epoch  4, batch     4 | loss: 5.5427399CurrentTrain: epoch  4, batch     5 | loss: 5.1508350CurrentTrain: epoch  4, batch     6 | loss: 5.1369495CurrentTrain: epoch  4, batch     7 | loss: 5.6158028CurrentTrain: epoch  4, batch     8 | loss: 5.7867661CurrentTrain: epoch  4, batch     9 | loss: 5.0270376CurrentTrain: epoch  4, batch    10 | loss: 5.2608099CurrentTrain: epoch  4, batch    11 | loss: 4.9322324CurrentTrain: epoch  4, batch    12 | loss: 5.6430264CurrentTrain: epoch  4, batch    13 | loss: 5.4462690CurrentTrain: epoch  4, batch    14 | loss: 5.1818523CurrentTrain: epoch  4, batch    15 | loss: 5.1185584CurrentTrain: epoch  4, batch    16 | loss: 5.5309782CurrentTrain: epoch  4, batch    17 | loss: 4.9648433CurrentTrain: epoch  4, batch    18 | loss: 5.1676154CurrentTrain: epoch  4, batch    19 | loss: 6.1134691CurrentTrain: epoch  4, batch    20 | loss: 6.1674781CurrentTrain: epoch  4, batch    21 | loss: 5.7961516CurrentTrain: epoch  4, batch    22 | loss: 5.8295503CurrentTrain: epoch  4, batch    23 | loss: 6.2899494CurrentTrain: epoch  4, batch    24 | loss: 5.3004279CurrentTrain: epoch  4, batch    25 | loss: 6.0179300CurrentTrain: epoch  4, batch    26 | loss: 5.3100019CurrentTrain: epoch  4, batch    27 | loss: 5.5023041CurrentTrain: epoch  4, batch    28 | loss: 4.9233627CurrentTrain: epoch  4, batch    29 | loss: 4.9410863CurrentTrain: epoch  4, batch    30 | loss: 4.9924817CurrentTrain: epoch  4, batch    31 | loss: 5.4026375CurrentTrain: epoch  4, batch    32 | loss: 4.9217744CurrentTrain: epoch  4, batch    33 | loss: 5.5592728CurrentTrain: epoch  4, batch    34 | loss: 4.9198790CurrentTrain: epoch  4, batch    35 | loss: 5.2177458CurrentTrain: epoch  4, batch    36 | loss: 5.2263017CurrentTrain: epoch  4, batch    37 | loss: 5.3536429CurrentTrain: epoch  5, batch     0 | loss: 5.4341989CurrentTrain: epoch  5, batch     1 | loss: 5.0973654CurrentTrain: epoch  5, batch     2 | loss: 5.5331159CurrentTrain: epoch  5, batch     3 | loss: 5.0171266CurrentTrain: epoch  5, batch     4 | loss: 5.5927324CurrentTrain: epoch  5, batch     5 | loss: 4.9855881CurrentTrain: epoch  5, batch     6 | loss: 5.5355449CurrentTrain: epoch  5, batch     7 | loss: 5.3561301CurrentTrain: epoch  5, batch     8 | loss: 5.2499228CurrentTrain: epoch  5, batch     9 | loss: 4.8273673CurrentTrain: epoch  5, batch    10 | loss: 5.1317067CurrentTrain: epoch  5, batch    11 | loss: 5.2944040CurrentTrain: epoch  5, batch    12 | loss: 4.9659357CurrentTrain: epoch  5, batch    13 | loss: 5.8766727CurrentTrain: epoch  5, batch    14 | loss: 6.1636901CurrentTrain: epoch  5, batch    15 | loss: 5.7009935CurrentTrain: epoch  5, batch    16 | loss: 4.9871421CurrentTrain: epoch  5, batch    17 | loss: 5.0103049CurrentTrain: epoch  5, batch    18 | loss: 4.9862108CurrentTrain: epoch  5, batch    19 | loss: 5.3728209CurrentTrain: epoch  5, batch    20 | loss: 4.9192219CurrentTrain: epoch  5, batch    21 | loss: 5.1885338CurrentTrain: epoch  5, batch    22 | loss: 5.2809200CurrentTrain: epoch  5, batch    23 | loss: 4.7714605CurrentTrain: epoch  5, batch    24 | loss: 5.3972812CurrentTrain: epoch  5, batch    25 | loss: 5.4070773CurrentTrain: epoch  5, batch    26 | loss: 5.1185827CurrentTrain: epoch  5, batch    27 | loss: 4.8482919CurrentTrain: epoch  5, batch    28 | loss: 5.3515248CurrentTrain: epoch  5, batch    29 | loss: 5.0164065CurrentTrain: epoch  5, batch    30 | loss: 4.8783207CurrentTrain: epoch  5, batch    31 | loss: 6.8375421CurrentTrain: epoch  5, batch    32 | loss: 4.8721528CurrentTrain: epoch  5, batch    33 | loss: 5.0599031CurrentTrain: epoch  5, batch    34 | loss: 4.8626556CurrentTrain: epoch  5, batch    35 | loss: 4.8439140CurrentTrain: epoch  5, batch    36 | loss: 4.7527962CurrentTrain: epoch  5, batch    37 | loss: 4.8936300CurrentTrain: epoch  6, batch     0 | loss: 5.0814848CurrentTrain: epoch  6, batch     1 | loss: 4.7797008CurrentTrain: epoch  6, batch     2 | loss: 4.9941978CurrentTrain: epoch  6, batch     3 | loss: 5.1156459CurrentTrain: epoch  6, batch     4 | loss: 4.7338419CurrentTrain: epoch  6, batch     5 | loss: 5.9523144CurrentTrain: epoch  6, batch     6 | loss: 4.8461833CurrentTrain: epoch  6, batch     7 | loss: 4.7898865CurrentTrain: epoch  6, batch     8 | loss: 4.9313498CurrentTrain: epoch  6, batch     9 | loss: 4.7509351CurrentTrain: epoch  6, batch    10 | loss: 4.8218575CurrentTrain: epoch  6, batch    11 | loss: 5.0126071CurrentTrain: epoch  6, batch    12 | loss: 5.1553540CurrentTrain: epoch  6, batch    13 | loss: 5.0261331CurrentTrain: epoch  6, batch    14 | loss: 5.0815172CurrentTrain: epoch  6, batch    15 | loss: 5.1128578CurrentTrain: epoch  6, batch    16 | loss: 5.1924381CurrentTrain: epoch  6, batch    17 | loss: 5.3671675CurrentTrain: epoch  6, batch    18 | loss: 4.7872906CurrentTrain: epoch  6, batch    19 | loss: 4.8254600CurrentTrain: epoch  6, batch    20 | loss: 5.0115561CurrentTrain: epoch  6, batch    21 | loss: 4.9450488CurrentTrain: epoch  6, batch    22 | loss: 5.0866089CurrentTrain: epoch  6, batch    23 | loss: 6.0847816CurrentTrain: epoch  6, batch    24 | loss: 4.8955870CurrentTrain: epoch  6, batch    25 | loss: 4.8825541CurrentTrain: epoch  6, batch    26 | loss: 5.1464272CurrentTrain: epoch  6, batch    27 | loss: 4.9154220CurrentTrain: epoch  6, batch    28 | loss: 4.7518215CurrentTrain: epoch  6, batch    29 | loss: 5.0594592CurrentTrain: epoch  6, batch    30 | loss: 4.7585158CurrentTrain: epoch  6, batch    31 | loss: 4.8069105CurrentTrain: epoch  6, batch    32 | loss: 5.2864518CurrentTrain: epoch  6, batch    33 | loss: 4.9359641CurrentTrain: epoch  6, batch    34 | loss: 5.5506940CurrentTrain: epoch  6, batch    35 | loss: 4.8813095CurrentTrain: epoch  6, batch    36 | loss: 4.9293456CurrentTrain: epoch  6, batch    37 | loss: 4.7937794CurrentTrain: epoch  7, batch     0 | loss: 4.7999616CurrentTrain: epoch  7, batch     1 | loss: 4.6797233CurrentTrain: epoch  7, batch     2 | loss: 4.7068706CurrentTrain: epoch  7, batch     3 | loss: 4.8167205CurrentTrain: epoch  7, batch     4 | loss: 4.8285394CurrentTrain: epoch  7, batch     5 | loss: 4.7724423CurrentTrain: epoch  7, batch     6 | loss: 5.1150770CurrentTrain: epoch  7, batch     7 | loss: 4.8143640CurrentTrain: epoch  7, batch     8 | loss: 4.9051180CurrentTrain: epoch  7, batch     9 | loss: 4.7531328CurrentTrain: epoch  7, batch    10 | loss: 4.7623692CurrentTrain: epoch  7, batch    11 | loss: 4.8227396CurrentTrain: epoch  7, batch    12 | loss: 5.1858792CurrentTrain: epoch  7, batch    13 | loss: 4.7734919CurrentTrain: epoch  7, batch    14 | loss: 4.7681270CurrentTrain: epoch  7, batch    15 | loss: 4.8891339CurrentTrain: epoch  7, batch    16 | loss: 4.8132114CurrentTrain: epoch  7, batch    17 | loss: 4.7038202CurrentTrain: epoch  7, batch    18 | loss: 4.9052558CurrentTrain: epoch  7, batch    19 | loss: 4.7920871CurrentTrain: epoch  7, batch    20 | loss: 5.3145146CurrentTrain: epoch  7, batch    21 | loss: 5.2278423CurrentTrain: epoch  7, batch    22 | loss: 5.1348529CurrentTrain: epoch  7, batch    23 | loss: 4.7209473CurrentTrain: epoch  7, batch    24 | loss: 4.9468508CurrentTrain: epoch  7, batch    25 | loss: 4.6984210CurrentTrain: epoch  7, batch    26 | loss: 4.8058786